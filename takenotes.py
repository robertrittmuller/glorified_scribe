import argparse  # for command line arguments
import io  # for file handling
import os  # to interact with operating system
import re  # for regular expressions
import speech_recognition as sr  # to recognize and convert speech
import whisper  # for transcription
import torch  # for data processing and deep learning tasks
import uuid  # for generating unique ID

from datetime import datetime, timedelta, timezone  # for tracking time
from queue import Queue  # for data transfer between threads
from tempfile import NamedTemporaryFile  # to create temporary files
from time import sleep  # to pause execution of the program
from sys import platform  # to get the platform (OS) details

# NLP / AI Configuration
import module_nlp as nlp_engine
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

ai = nlp_engine.nlp(openAI=True)

# helper functions
def save_transcription(transcription, file_stub="transcript"):
    """
    Function to save the generated transcription into a file. The filename is
    generated by a combination of a unique ID and timestamp.
    
    Parameters:
    transcription (list): The list containing transcriptions to be saved.
    """
    # Generate a unique ID for the filename
    unique_id = uuid.uuid4()
    # Generate current timestamp for the filename
    timestamp = datetime.now().strftime('%Y%m%d%H%M')
    # Combine unique ID and timestamp to form the filename
    filename = f"{str(file_stub)}-{timestamp}-{str(unique_id)}.txt"
    
    # Open the file in write mode and save the transcription
    if isinstance(transcription, list):
        with open(filename, 'w') as f:
            for line in transcription:
                f.write(f"{line}\n")
    else:
        with open(filename, 'w') as f:
            f.write(f"{transcription}")

def process_transcript(transcript):
    # run through the NLP pipeline
    cleaned_transcript = None
    summerized_transcript = None

    cleaned_transcript = ai.openai_cleaning(transcript)
    if(cleaned_transcript != None):
        summerized_transcript = ai.openai_summerization(cleaned_transcript)
    
    return cleaned_transcript, summerized_transcript

def read_text_file(file_path):
    try:
        with open(file_path, 'r') as file:
            text = file.read()
        return text
    except FileNotFoundError:
        print(f"File '{file_path}' not found.")
        return None
    except IOError:
        print(f"Error reading file '{file_path}'.")
        return None

def main():
    # Setting up argparse for command line arguments
    parser = argparse.ArgumentParser()
    # Setting up choices for models, default as "medium"
    parser.add_argument("--model", default="medium", help="Model to use", choices=["tiny", "base", "small", "medium", "large"])
    # Flag for if you want to process a file using the AI only, no live transcription
    parser.add_argument("--file", default="", help="File to process")
    # Flag for if the input file is from Microsoft Teams (transcript format)
    parser.add_argument("--teams", action='store_true', help="Input file is a Microsoft Teams transcript.")
    # Flag for whether to use the non-English model
    parser.add_argument("--non_english", action='store_true', help="Don't use the english model.")
    # Setting up energy level for microphone to detect, default as 1000
    parser.add_argument("--energy_threshold", default=1000, help="Energy level for mic to detect.", type=int)
    # Setting up real time recording timeout, default as 2 seconds
    parser.add_argument("--record_timeout", default=2, help="How real time the recording is in seconds.", type=float)
    # Setting up empty space timeout between recordings, default as 3 seconds
    parser.add_argument("--phrase_timeout", default=3, help="How much empty space between recordings before we consider it a new line in the transcription.", type=float)  

    # Setting up microphone for Linux platforms
    if 'linux' in platform:
        parser.add_argument("--default_microphone", default='pulse', help="Default microphone name for SpeechRecognition. Run this with 'list' to view available Microphones.", type=str)
    
    # Parse command line arguments
    args = parser.parse_args()

    # setup prompts based on command line toggles
    if(args.teams == True):
        ai.cleaning_command_text = ai.get_prompt('cleaning_prompt_teams')
        ai.summerization_command_text = ai.get_prompt('summerization_prompt_teams')
        print('Processing as a Microsoft Teams transcript...')
    else:
        ai.cleaning_command_text = ai.get_prompt('cleaning_prompt_default')
        ai.summerization_command_text = ai.get_prompt('summerization_prompt_default')

    # Initialize variables
    phrase_time = None  # last time a recording was retrieved from the queue
    last_sample = bytes()  # current raw audio bytes
    data_queue = Queue()  # Thread safe Queue for passing data from the threaded recording callback
    recorder = sr.Recognizer()  # SpeechRecognizer object for recording
    recorder.energy_threshold = args.energy_threshold  # Set energy threshold for microphone
    recorder.dynamic_energy_threshold = False  # Disabling dynamic energy threshold to prevent continuous recording
    
    # Setting up microphone for Linux platforms to prevent app hang and crash
    if 'linux' in platform:
        mic_name = args.default_microphone
        if not mic_name or mic_name == 'list':
            print("Available microphone devices are: ")
            for index, name in enumerate(sr.Microphone.list_microphone_names()):
                print(f"Microphone with name \"{name}\" found")   
            return
        else:
            for index, name in enumerate(sr.Microphone.list_microphone_names()):
                if mic_name in name:
                    source = sr.Microphone(sample_rate=16000, device_index=index)
                    break
    else:
        source = sr.Microphone(sample_rate=16000)
        
    # Load / Download speech model
    model = args.model
    if args.model != "large" and not args.non_english:
        model = model + ".en"
    audio_model = whisper.load_model(model)

    # Set record and phrase timeouts
    record_timeout = args.record_timeout
    phrase_timeout = args.phrase_timeout

    # Create a temporary file for transcription
    temp_file = NamedTemporaryFile().name
    transcription = ['']
    
    # Adjust for ambient noise
    with source:
        recorder.adjust_for_ambient_noise(source)

    def record_callback(_, audio:sr.AudioData) -> None:
        """
        Threaded callback function to receive audio data when recordings finish.
        audio: An AudioData containing the recorded bytes.
        """
        data = audio.get_raw_data()  # get raw bytes of audio data
        data_queue.put(data)  # push it into the thread safe queue

    # Create a background thread for recording
    recorder.listen_in_background(source, record_callback, phrase_time_limit=record_timeout)

    print("Model loaded.\n")

    # Main loop for recording and transcribing only if we are not processing a file
    if(args.file == ""):
        while True:
            try:
                now = datetime.now(timezone.utc)
                # If data available in the queue, process it
                if not data_queue.empty():
                    phrase_complete = False  # Flag to track if phrase is complete
                    # If enough time has passed between recordings, consider the phrase complete and reset the buffer
                    if phrase_time and now - phrase_time > timedelta(seconds=phrase_timeout):
                        last_sample = bytes()
                        phrase_complete = True
                    phrase_time = now  # update last received audio time

                    # Concatenate all data in the queue
                    while not data_queue.empty():
                        data = data_queue.get()
                        last_sample += data

                    # Convert raw audio data to wav format
                    audio_data = sr.AudioData(last_sample, source.SAMPLE_RATE, source.SAMPLE_WIDTH)
                    wav_data = io.BytesIO(audio_data.get_wav_data())

                    # Write wav data to temporary file
                    with open(temp_file, 'w+b') as f:
                        f.write(wav_data.read())

                    # Transcribe audio data
                    result = audio_model.transcribe(temp_file, fp16=torch.cuda.is_available())
                    text = result['text'].strip()

                    # Update transcription based on whether phrase is complete
                    if phrase_complete:
                        transcription.append(text)
                    else:
                        transcription[-1] = text

                    # Clear console and print updated transcription
                    os.system('cls' if os.name=='nt' else 'clear')
                    for line in transcription:
                        print(line)
                    print('', end='', flush=True)  # flush stdout

                    sleep(0.25)  # prevent infinite loop
            except KeyboardInterrupt:
                break  # stop recording when KeyboardInterrupt is raised

        # Print final transcription
        print("\n\nTranscription:")
        for line in transcription:
            print(line)

        # Save the transcription to a file
        save_transcription(transcription)
    
    if ai.num_words(transcription) > 100:
        # if there is enough words, let's process the transcript
        pass
    else:
        if(args.file != ""):
            # read in the file
            transcription = read_text_file(args.file)
            # process the transcript
            cleaned_transcript, summerized_transcript = process_transcript(transcription)
            # save the cleaned and summerized transcript
            if(cleaned_transcript != None):
                save_transcription(cleaned_transcript, file_stub="cleaned")
            if(summerized_transcript != None):
                summerized_transcript += "\n\nDetailed Meeting Notes: \n"
                summerized_transcript += cleaned_transcript
                save_transcription(summerized_transcript, file_stub="summary")
        else:
            print("Transcript is not long enough to process into a sumamry!")


# Run the main function
if __name__ == "__main__":
    main()